{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from dataset_utilits import load_imagesPath_ages_sex\n",
    "from inception_utilits import stem_block, inception_a_block, inception_b_block, inception_c_block, reduction_a_block, \\\n",
    "    reduction_b_block\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_truth = pd.read_csv('./data/train/train.csv')\n",
    "validation_truth = pd.read_csv('./data/validation/validation.csv')\n",
    "test_truth = pd.read_excel('./data/test/test.xlsx')\n",
    "IMG_SHAPE = (299, 299, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prendo le image_names da  C:\\Users\\Victor\\Development\\BDMA\\UniPd\\HDA\\HDA-bone-age-prediction\\data\\train\\reshaped\n",
      "prendo le image_names da  C:\\Users\\Victor\\Development\\BDMA\\UniPd\\HDA\\HDA-bone-age-prediction\\data\\validation\\reshaped\n",
      "prendo le image_names da  C:\\Users\\Victor\\Development\\BDMA\\UniPd\\HDA\\HDA-bone-age-prediction\\data\\test\\reshaped\n"
     ]
    }
   ],
   "source": [
    "path_data_dir = 'data'\n",
    "full_path = os.path.join(os.getcwd(), path_data_dir)\n",
    "X_train, age_train, sex_train, X_validation, age_validation, sex_validation, X_test, age_test, sex_test = load_imagesPath_ages_sex(\n",
    "    full_path, train_truth, validation_truth, test_truth, None)\n",
    "\n",
    "age_train = [x / 200. for x in age_train]\n",
    "age_validation = [x / 200. for x in age_validation]\n",
    "age_test = [x / 200. for x in age_test]\n",
    "\n",
    "age_train_df = pd.DataFrame(age_train, columns=['age'])\n",
    "age_validation_df = pd.DataFrame(age_validation, columns=['age'])\n",
    "age_test_df = pd.DataFrame(age_test, columns=['age'])\n",
    "\n",
    "age_train_df = age_train_df.astype('float32')\n",
    "age_validation_df = age_validation_df.astype('float32')\n",
    "age_test_df = age_test_df.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: 200\n",
      "X train shape: 12600\n",
      "X val shape: 1424\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", len(X_test))\n",
    "print(\"X train shape:\", len(X_train))\n",
    "print(\"X val shape:\", len(X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['C:\\\\Users\\\\Victor\\\\Development\\\\BDMA\\\\UniPd\\\\HDA\\\\HDA-bone-age-prediction\\\\data\\\\test\\\\reshaped\\\\4360.png',\n 'C:\\\\Users\\\\Victor\\\\Development\\\\BDMA\\\\UniPd\\\\HDA\\\\HDA-bone-age-prediction\\\\data\\\\test\\\\reshaped\\\\4361.png',\n 'C:\\\\Users\\\\Victor\\\\Development\\\\BDMA\\\\UniPd\\\\HDA\\\\HDA-bone-age-prediction\\\\data\\\\test\\\\reshaped\\\\4362.png',\n 'C:\\\\Users\\\\Victor\\\\Development\\\\BDMA\\\\UniPd\\\\HDA\\\\HDA-bone-age-prediction\\\\data\\\\test\\\\reshaped\\\\4363.png',\n 'C:\\\\Users\\\\Victor\\\\Development\\\\BDMA\\\\UniPd\\\\HDA\\\\HDA-bone-age-prediction\\\\data\\\\test\\\\reshaped\\\\4364.png']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second branch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('./data/train/maxes.csv')\n",
    "train_features['image'] = train_features['image'].str[:-4].astype(int)\n",
    "second_branch_df_train = pd.merge(train_features, train_truth, left_on='image', right_on='id')\n",
    "second_branch_df_train = second_branch_df_train.drop(['id', 'image', 'boneage'], axis=1).rename({'male': 'sex'}, axis=1)\n",
    "second_branch_df_train['sex'] = second_branch_df_train['sex'].replace({True: 1, False: 0})\n",
    "\n",
    "validation_features = pd.read_csv('./data/validation/maxes.csv')\n",
    "validation_features['image'] = validation_features['image'].str[:-4].astype(int)\n",
    "second_branch_df_val = pd.merge(validation_features, validation_truth, left_on='image', right_on='Image ID')\n",
    "second_branch_df_val = second_branch_df_val.drop(['Image ID', 'image', 'Bone Age (months)'], axis=1).rename(\n",
    "    {'male': 'sex'}, axis=1)\n",
    "second_branch_df_val['sex'] = second_branch_df_val['sex'].replace({True: 1, False: 0})\n",
    "\n",
    "test_features = pd.read_csv('./data/test/maxes.csv')\n",
    "test_features['image'] = test_features['image'].str[:-4].astype(int)\n",
    "second_branch_df_test = pd.merge(test_features, test_truth, left_on='image', right_on='Case ID')\n",
    "second_branch_df_test = second_branch_df_test.drop(['Case ID', 'image', 'Ground truth bone age (months)'],\n",
    "                                                   axis=1).rename({'Sex': 'sex'}, axis=1)\n",
    "second_branch_df_test['sex'] = second_branch_df_test['sex'].replace({'M': 1, 'F': 0})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try if the second branch works by itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataset_branch2(second_branch_df, ages, batch_size, shuffle, cache_file=None):\n",
    "\n",
    "#     # Create a Dataset object\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((second_branch_df, ages))\n",
    "\n",
    "#     # Cache dataset\n",
    "#     if cache_file:\n",
    "#         dataset = dataset.cache(cache_file)\n",
    "\n",
    "\n",
    "#     # Shuffle\n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(len(second_branch_df))\n",
    "\n",
    "#     # Repeat the dataset indefinitely\n",
    "#     dataset = dataset.repeat()\n",
    "\n",
    "#     # Batch\n",
    "#     dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "#     # Prefetch\n",
    "#     dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "#     return dataset\n",
    "\n",
    "# batch_size = 32\n",
    "# train_dataset_branch_2 = create_dataset_branch2(second_branch_df = second_branch_df_train, \n",
    "#                     ages = age_train, \n",
    "#                     batch_size = batch_size, \n",
    "#                     shuffle = False )  \n",
    "\n",
    "# validation_dataset_branch_2 = create_dataset_branch2(second_branch_df = second_branch_df_val, \n",
    "#                     ages = age_validation, \n",
    "#                     batch_size = batch_size, \n",
    "#                     shuffle = False ) \n",
    "\n",
    "# def dense_branch_2(X_input):\n",
    "#     X = Dense(64, activation='relu', name='first_dense_branch_2')(X_input)\n",
    "#     X = Dense(32, activation='relu', name='second_dense_branch_2')(X)\n",
    "#     X = Flatten()(X)\n",
    "#     # max_pooling o global_pooling (valore unico) [regolarizza vs overfitting] o dense più piccolo - > dense + pooling\n",
    "#     return X\n",
    "\n",
    "\n",
    "# def model_assembly_example(input_shape_dataset):\n",
    "#     # branch 2\n",
    "#     X_input_branch2 = Input(input_shape_dataset)\n",
    "#     branch2 = dense_branch_2(X_input_branch2)\n",
    "#     X = Dense(1, activation = 'relu', name='final')(branch2)\n",
    "\n",
    "\n",
    "#     # Create model\n",
    "#     model = Model(inputs = X_input_branch2, outputs = X, name='branch2_attempt')\n",
    "#     return model\n",
    "\n",
    "# train_steps = int(np.ceil(len(sex_train) / batch_size))\n",
    "# val_steps = int(np.ceil(len(sex_validation) / batch_size))\n",
    "\n",
    "# model = model_assembly_example(input_shape_dataset=5)\n",
    "\n",
    "# model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=tf.keras.metrics.mean_squared_error)\n",
    "\n",
    "# # Create a callback for early stopping \n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# history = model.fit(train_dataset_branch_2, \n",
    "#                     validation_data = validation_dataset_branch_2, \n",
    "#                     epochs=100, \n",
    "#                     steps_per_epoch=train_steps,\n",
    "#                     validation_steps=val_steps,\n",
    "#                     callbacks=[callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inceptionv4(X_input):  #  (input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception-v4 architecture\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # # Define the input as a tensor with shape input_shape (1 line)\n",
    "    # X_input = Input(input_shape)\n",
    "\n",
    "    # Call the above functions for the stem, inception-a, reduction-a, inception-b, reduction-b and inception-c blocks\n",
    "    X = stem_block(X_input)\n",
    "\n",
    "    # Four Inception A blocks\n",
    "    X = inception_a_block(X, 'a1')\n",
    "    X = inception_a_block(X, 'a2')\n",
    "    X = inception_a_block(X, 'a3')\n",
    "    X = inception_a_block(X, 'a4')\n",
    "\n",
    "    # Reduction A block\n",
    "    X = reduction_a_block(X)\n",
    "\n",
    "    # Seven Inception B blocks\n",
    "    X = inception_b_block(X, 'b1')\n",
    "    X = inception_b_block(X, 'b2')\n",
    "    X = inception_b_block(X, 'b3')\n",
    "    X = inception_b_block(X, 'b4')\n",
    "    X = inception_b_block(X, 'b5')\n",
    "    X = inception_b_block(X, 'b6')\n",
    "    X = inception_b_block(X, 'b7')\n",
    "\n",
    "    # Reduction B block\n",
    "    X = reduction_b_block(X)\n",
    "\n",
    "    # Three Inception C blocks\n",
    "    X = inception_c_block(X, 'c1')\n",
    "    X = inception_c_block(X, 'c2')\n",
    "    X = inception_c_block(X, 'c3')\n",
    "\n",
    "    # AVGPOOL (1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    kernel_pooling = X.get_shape()[1:3]\n",
    "    X = AveragePooling2D(kernel_pooling, name='avg_pool')(X)\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    # Dropout\n",
    "    X = Dropout(rate=0.2)(X)\n",
    "\n",
    "    # Output layer\n",
    "    # X = Dense(1, activation='relu', name='fc')(X)\n",
    "\n",
    "    # # Create model\n",
    "    # model = Model(inputs = X_input, outputs = X, name='Inceptionv4')\n",
    "\n",
    "    # return model\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_branch_2(X_input):\n",
    "    X = Dense(64, activation='relu', name='first_dense_branch_2')(X_input)\n",
    "    X = Dense(32, activation='relu', name='second_dense_branch_2')(X)\n",
    "    X = Flatten()(X)\n",
    "    # max_pooling o global_pooling (valore unico) [regolarizza vs overfitting] o dense più piccolo - > dense + pooling\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_2(path_df, label):\n",
    "    # Desired size\n",
    "    # num_row = IMG_SHAPE[1]\n",
    "    # num_col = IMG_SHAPE[0]\n",
    "    size = IMG_SHAPE[1]\n",
    "    path, df = path_df\n",
    "\n",
    "    # Get the image\n",
    "    img = tf.io.read_file(path)\n",
    "    # Decode the PNG\n",
    "    img = tf.image.decode_png(img)\n",
    "    # Resize image\n",
    "    img = tf.image.resize(img, (size, size))\n",
    "    # Reshape image (this is not necessary but I do it so that I don't need to be modifying the shape in the input layer)\n",
    "    #img = tf.reshape(img, [size, size, 3])\n",
    "    # Cast image to float32\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    # Normalize image\n",
    "    img = img / 255.0\n",
    "\n",
    "    return (img, df), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_images(img_paths, second_branch_df, ages, batch_size, shuffle, cache_file=None, repeat=True):\n",
    "    # Create a Dataset object\n",
    "    second_branch_df = second_branch_df.astype('float32')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((img_paths, second_branch_df), ages)).map(process_image_2)\n",
    "\n",
    "    # Cache dataset\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "\n",
    "    # Shuffle\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(img_paths))\n",
    "\n",
    "    # Repeat the dataset indefinitely\n",
    "    if repeat:\n",
    "        dataset = dataset.repeat()\n",
    "\n",
    "    # Batch\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "\n",
    "    # Prefetch\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "train_dataset = create_dataset_images(img_paths=X_train,\n",
    "                                      second_branch_df=second_branch_df_train[['sex']],  # Only gender\n",
    "                                      # second_branch_df=second_branch_df_train,   # Full features\n",
    "                                      ages=age_train_df,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=False)\n",
    "\n",
    "validation_dataset = create_dataset_images(img_paths=X_validation,\n",
    "                                           second_branch_df=second_branch_df_val[['sex']],  # Only gender\n",
    "                                           # second_branch_df=second_branch_df_val,  # Full features\n",
    "                                           ages=age_validation_df,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "train_steps = int(np.ceil(len(X_train) / batch_size))\n",
    "validation_steps = int(np.ceil(len(X_validation) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_assembly(input_shape_img, input_shape_dataset):\n",
    "    # Branch 1\n",
    "    X_input_branch1 = Input(input_shape_img)\n",
    "    branch1 = Inceptionv4(X_input_branch1)\n",
    "\n",
    "    # # Branch 2\n",
    "    X_input_branch2 = Input(input_shape_dataset)\n",
    "    branch2 = dense_branch_2(X_input_branch2)\n",
    "\n",
    "    # # Concatenate branch1 and branch2\n",
    "    X = tf.concat(values=[branch1, branch2], axis=1)\n",
    "    X = Dense(1000, activation='relu', name='final_dense_1')(X)\n",
    "    X = Dense(1000, activation='relu', name='final_dense_2')(X)\n",
    "    X_out = Dense(1, activation='linear', name='final')(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=(X_input_branch1, X_input_branch2), outputs=X_out, name='model0')  #  X_input_branch2\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model = model_assembly(input_shape_img=IMG_SHAPE, input_shape_dataset=1)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=tf.keras.metrics.mean_squared_error)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Create a callback for early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Callback for tensorboard\n",
    "log_dir = \"./logs/base_fixed_50_epochs\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "checkpoint_path = \"./checkpoints/base_fixed_50_epochs/\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.1172 - mean_squared_error: 0.1172\n",
      "Epoch 1: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 479s 295ms/step - loss: 0.1172 - mean_squared_error: 0.1172 - val_loss: 36.5667 - val_mean_squared_error: 36.5667\n",
      "Epoch 2/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 2: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 468s 297ms/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 3/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0187 - mean_squared_error: 0.0187\n",
      "Epoch 3: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 466s 296ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 4/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0169\n",
      "Epoch 4: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 463s 294ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
      "Epoch 5: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 474s 301ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 6/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0121 - mean_squared_error: 0.0121\n",
      "Epoch 6: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 491s 311ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "Epoch 7/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 7: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 488s 310ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "Epoch 8/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096\n",
      "Epoch 8: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 480s 304ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "Epoch 9/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0099 - mean_squared_error: 0.0099\n",
      "Epoch 9: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 465s 295ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
      "Epoch 10/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 10: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 466s 296ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 11/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 11: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 468s 297ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
      "Epoch 12/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 12: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 469s 297ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 13/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 13: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 469s 298ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
      "Epoch 14/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 14: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 468s 297ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
      "Epoch 15/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 15: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 465s 295ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
      "Epoch 16/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 16: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 468s 297ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 17/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 17: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 470s 298ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 18/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 18: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 470s 298ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 19/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 19: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 478s 303ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 20/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 20: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 484s 307ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 21/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 21: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 486s 308ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 22/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 22: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 469s 297ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
      "Epoch 23/50\n",
      "1575/1575 [==============================] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 23: saving model to ./checkpoints/base_fixed_50_epochs\\\n",
      "1575/1575 [==============================] - 488s 310ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
      "Epoch 24/50\n",
      "1086/1575 [===================>..........] - ETA: 2:16 - loss: 0.0030 - mean_squared_error: 0.0030"
     ]
    }
   ],
   "source": [
    "# Fit the model on batches with real-time data augmentation:\n",
    "history = model.fit(train_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=50,\n",
    "                    # initial_epoch=14,\n",
    "                    steps_per_epoch=train_steps,\n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[tensorboard_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 149). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/base_50_epochs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/base_50_epochs\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/base_fixed_50_epochs')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test_dataset = create_dataset_images(img_paths=X_test,\n",
    "                                     second_branch_df=second_branch_df_test[['sex']],\n",
    "                                     ages=age_test_df,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     repeat=False)\n",
    "second_validation = create_dataset_images(img_paths=X_validation,\n",
    "                                          second_branch_df=second_branch_df_val[['sex']],\n",
    "                                          ages=age_validation_df,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          repeat=False)\n",
    "second_train = create_dataset_images(img_paths=X_train,\n",
    "                                     second_branch_df=second_branch_df_train[['sex']],\n",
    "                                     ages=age_train_df,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     repeat=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 5s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "     Model ouput  Output Age  Real Age  Real Age Months     Error  \\\n0       0.844615  168.922913     0.840       168.000000  0.004615   \n1       0.869985  173.997040     0.845       169.000000  0.024985   \n2       0.385227   77.045471     0.365        73.000000  0.020227   \n3       0.741997  148.399475     0.760       152.000000 -0.018003   \n4       0.714468  142.893677     0.675       135.000000  0.039468   \n..           ...         ...       ...              ...       ...   \n195     0.731814  146.362762     0.665       133.000000  0.066814   \n196     0.657595  131.519073     0.645       129.000000  0.012595   \n197     0.815840  163.168091     0.835       167.000000 -0.019159   \n198     0.653619  130.723740     0.675       135.000000 -0.021381   \n199     0.576586  115.317177     0.590       117.999992 -0.013414   \n\n     Error Months  Absolute Error  Squared Error  \n0        0.922918        0.004615       0.000021  \n1        4.997039        0.024985       0.000624  \n2        4.045468        0.020227       0.000409  \n3       -3.600526        0.018003       0.000324  \n4        7.893682        0.039468       0.001558  \n..            ...             ...            ...  \n195     13.362753        0.066814       0.004464  \n196      2.519071        0.012595       0.000159  \n197     -3.831899        0.019159       0.000367  \n198     -4.276264        0.021381       0.000457  \n199     -2.682817        0.013414       0.000180  \n\n[200 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model ouput</th>\n      <th>Output Age</th>\n      <th>Real Age</th>\n      <th>Real Age Months</th>\n      <th>Error</th>\n      <th>Error Months</th>\n      <th>Absolute Error</th>\n      <th>Squared Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.844615</td>\n      <td>168.922913</td>\n      <td>0.840</td>\n      <td>168.000000</td>\n      <td>0.004615</td>\n      <td>0.922918</td>\n      <td>0.004615</td>\n      <td>0.000021</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.869985</td>\n      <td>173.997040</td>\n      <td>0.845</td>\n      <td>169.000000</td>\n      <td>0.024985</td>\n      <td>4.997039</td>\n      <td>0.024985</td>\n      <td>0.000624</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.385227</td>\n      <td>77.045471</td>\n      <td>0.365</td>\n      <td>73.000000</td>\n      <td>0.020227</td>\n      <td>4.045468</td>\n      <td>0.020227</td>\n      <td>0.000409</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.741997</td>\n      <td>148.399475</td>\n      <td>0.760</td>\n      <td>152.000000</td>\n      <td>-0.018003</td>\n      <td>-3.600526</td>\n      <td>0.018003</td>\n      <td>0.000324</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.714468</td>\n      <td>142.893677</td>\n      <td>0.675</td>\n      <td>135.000000</td>\n      <td>0.039468</td>\n      <td>7.893682</td>\n      <td>0.039468</td>\n      <td>0.001558</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>0.731814</td>\n      <td>146.362762</td>\n      <td>0.665</td>\n      <td>133.000000</td>\n      <td>0.066814</td>\n      <td>13.362753</td>\n      <td>0.066814</td>\n      <td>0.004464</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>0.657595</td>\n      <td>131.519073</td>\n      <td>0.645</td>\n      <td>129.000000</td>\n      <td>0.012595</td>\n      <td>2.519071</td>\n      <td>0.012595</td>\n      <td>0.000159</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>0.815840</td>\n      <td>163.168091</td>\n      <td>0.835</td>\n      <td>167.000000</td>\n      <td>-0.019159</td>\n      <td>-3.831899</td>\n      <td>0.019159</td>\n      <td>0.000367</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>0.653619</td>\n      <td>130.723740</td>\n      <td>0.675</td>\n      <td>135.000000</td>\n      <td>-0.021381</td>\n      <td>-4.276264</td>\n      <td>0.021381</td>\n      <td>0.000457</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>0.576586</td>\n      <td>115.317177</td>\n      <td>0.590</td>\n      <td>117.999992</td>\n      <td>-0.013414</td>\n      <td>-2.682817</td>\n      <td>0.013414</td>\n      <td>0.000180</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Model ouput'])\n",
    "results_df['Output Age'] = results_df['Model ouput'] * 200\n",
    "results_df['Real Age'] = age_test_df\n",
    "results_df['Real Age Months'] = age_test_df * 200\n",
    "results_df['Error'] = results_df['Model ouput'] - results_df['Real Age']\n",
    "results_df['Error Months'] = results_df['Error'] * 200\n",
    "results_df['Absolute Error'] = results_df['Error'].abs()\n",
    "results_df['Squared Error'] = results_df['Error'] ** 2\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04524028 9.048055857419968\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(results_df['Absolute Error']), np.mean(results_df['Absolute Error']) * 200)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197.98154 14.070591\n"
     ]
    }
   ],
   "source": [
    "mse = np.mean((results_df['Absolute Error'] * 200) ** 2)\n",
    "print(mse, np.sqrt(mse))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "full_model = tf.keras.models.load_model('./models/full_50_epochs')\n",
    "full_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 96ms/step\n"
     ]
    }
   ],
   "source": [
    "results = full_model.predict(test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc7584d7085398ca59d1bc7417060e07bb5363bf245a5ad688f6fa83be570210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
